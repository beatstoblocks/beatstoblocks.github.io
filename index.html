<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Beats To Blocks</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 20px;
        }

        h1 {
            color: #333;
        }

        h2 {
            color: #555;
        }

        p {
            color: #777;
        }

        code {
            background-color: #f8f8f8;
            padding: 2px 4px;
            color: #333;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
        }

        .section {
            margin-bottom: 20px;
        }

        .pipeline {
            margin-bottom: 10px;
        }
    </style>
</head>
<body>

    <h1>Beats To Blocks</h1>
    <p><strong>By Peter Akedemir, Dustin La, Joshua Quizon, Rahul Shah</strong></p>

    <div class="section">
        <h2>Overview</h2>
        <p>Given any song in a .wav file format, split the song into its 
            unique stems and convert it to MIDI format. Using the MIDI 
            file, create a Minecraft Note Block cover (audio only) using 
            the same or similar instruments used within the original song. 
            This program will allow any song to be converted into a 
            Minecraft Note Block cover automatically without needing 
            to identify notes manually and creating a MIDI file for 
            the song or creating within Minecraft itself. 
        </p>
    </div>

    <div class="section">
        <h2>Motivation</h2>
        <p>There are many covers of existing songs that are made using 
            Minecraft note blocks, however the process of converting 
            these songs to note block format is obscure. 
            This project aims to automate the transcription 
            process using a model to transform a song to MIDI format, 
            and MIDI format to a set of Minecraft note blocks. 
            While the production level version of this project 
            can be used to create more noteblock covers for existing 
            songs, the main motivation behind it is the interesting and 
            “cool” aspect of audio transcription.</p>
    </div>

    <br>
    <div class="section">
        <h2>Machine Listening Models</h2>
        <h3>Spleeter</h3>
        <p>A music source separation tool that uses pre-trained models. 
            It takes in a waveform as input, and outputs a 5 splits max: 
            vocals, drums, bass, piano, and other. Research papers state 
            that it is one of the best performing 4-stem separation models
            using the musdb18 benchmark.</p>

        <h3>Demucs</h3>
        <p>Short for “Deep Extractor for Music Sources,” it is a 
            stem splitting model that takes in a waveform as input. 
            The output is a 4-way split of bass, drums, vocals, and 
            other sounds. Specifically, the version of Demucs being 
            used is an implementation using Transforms, which performs 
            better by accounting for both long and short music content.  
            In research papers, it has been stated to perform better 
            source separation for bass and drum splits.</p>
        
        <h3>MT3</h3>
        <p>A music transcription model that takes a waveform as 
            input and transcribes it to a MIDI equivalent. 
            It performs well in regards to evaluating how accurate 
            its estimations of frames, onsets, and offsets are. 
            While MT3 is not a lightweight technology, it is very 
            strong in its transcription capabilities–it can detect
            multiple instruments and notes played by those instruments.
        </p>
            
        <h3>Spotify Basic Pitch</h3>
        <p>In the context of automatic music transcription, 
            Basic Pitch aims to deliver a product that is both powerful, 
            but lightweight enough to be used in a production environment. 
            The library accepts a waveform as input, and translates it 
            into MIDI format. Performance demonstrates that the system 
            exceeds the benchmark of other AMT systems in terms of 
            frame-wise onset, multipitch, and note-activation estimations. 
            It is important to note that unlike MT3, Basic Pitch only 
            estimates notes, not instruments.
        </p>
    </div>
    <br>
    <div class="section">
        <h2>Open Note Block Studio</h2>
        <p>Open Note Block Studio is a software that allows users to 
            create MIDI files and map to Minecraft Note Blocks through 
            a graphical user interface. Within our program, we can create 
            our own Minecraft Note Block Studio (NBS) files using the 
            opennbs python package. To create our final audio outputs, 
            we use the nbswave python package transform the nbs file 
            into a .wav file. 
        </p>
    </div>

    <br>
    <div class="section">
        <h2>Pipelines</h2>
        <h3>Pipeline #1 - MT3 Only</h3>
        <p>This pipeline only uses the MT3 model. 
            It transcribes the original source file and uses it as 
            input for MT3.</p>
            <h3>Pipeline #2 - Demucs, Spleeter, MT3</h3>
            <p>This pipeline uses Demucs to split the track into bass, drums, vocals, and other sounds. 
                It then splits the other stems through Spleeter to obtain the piano and other stems separately. 
                Finally, it transcribes all of these files through MT3. The specific files chosen for this pipeline are:
                <ul>
                    <li>Demucs with Spleeter: Piano.mid, Other.mid</li>
                    <li>Demucs: Drums.mid, Bass.mid</li>
                </ul>
            </p>
            
            <h3>Pipeline #3 - Spleeter and MT3</h3>
            <p>This pipeline uses Spleeter to split the track into piano, drums, bass, and other. 
                These stems are then transcribed into MIDI using MT3. The specific files chosen for this pipeline are:
                <ul>
                    <li>Piano.mid</li>
                    <li>Drums.mid</li>
                    <li>Bass.mid</li>
                    <li>Other.mid</li>
                </ul>
            </p>
            
            <h3>Pipeline #4 - Demucs, Spleeter, Spotify Basic Pitch</h3>
            <p>This pipeline uses Demucs to split the track into bass, drums, vocals, and other sounds. 
                It then splits the other stems through Spleeter to obtain the piano and other stems separately. 
                Finally, it transcribes all of these files through Spotify Basic Pitch. The specific files chosen for this pipeline are:
                <ul>
                    <li>Demucs with Spleeter: Piano.mid, Other.mid</li>
                    <li>Demucs: Drums.mid, Bass.mid</li>
                </ul>
            </p>
            
            <h3>Pipeline #5 - Spleeter and Spotify Basic Pitch</h3>
            <p>This pipeline uses Spleeter to split the track into piano, drums, bass, and other. 
                These stems are then transcribed into MIDI using Spotify Basic Pitch. The specific files chosen for this pipeline are:
                <ul>
                    <li>Piano.mid</li>
                    <li>Drums.mid</li>
                    <li>Bass.mid</li>
                    <li>Other.mid</li>
                </ul>
            </p>
            
    </div>

    <!-- Continue with other sections... -->

</body>
</html>
